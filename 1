# -*- coding: utf-8 -*-
import sys
import re
from operator import add

from pyspark import SparkContext

def map_phase(x):
    x = re.sub('--', ' ', x)
    x = re.sub("'", '', x)
    return re.sub('[?!@#$\'",.;:()]', '', x).lower()

if __name__ == "__main__":
	if len(sys.argv) < 4:
	    print >> sys.stderr, "Usage: wordcount <master> <inputfile> <outputfile>"
	    exit(-1)
	sc = SparkContext(sys.argv[1], "python_wordcount_sorted in bigdataprogrammiing")
	lines = sc.textFile(sys.argv[2],2) # input file parition 2개로 설정. 3개,4개로 설정해볼것.
	print("number of partitions: ", lines.getNumPartitions()) # print the number of partitions
	print("lines: ", lines)
		
	lines = lines.map(labmda x => map_phase(x))
	print("collect: ", lines.collect())
	#
	#
	outRDD.saveAsTextFile()
